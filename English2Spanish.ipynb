{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YywPwhl59D2",
        "outputId": "9b4e486f-c72e-4584-957b-5b5a18917d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchinfo import summary\n",
        "from my_transformer import Transformer\n",
        "from my_train import train\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "N1yMRd-K6gb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aux(line):\n",
        "  line = line.replace('.', '')\n",
        "  line = line.replace(',', '')\n",
        "  line = line.replace('!', '')\n",
        "  line = line.replace('?', '')\n",
        "  return line"
      ],
      "metadata": {
        "id": "UPYRsDo-1ldi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "English_sens = []\n",
        "Spanish_sens = []\n",
        "with open('/content/spa.txt', 'r') as f:\n",
        "  for line in f.readlines():\n",
        "    en, sp = line.split('CC')[0].split('\\t')[:-1]\n",
        "    en = aux(en.lower())\n",
        "    sp = '<st> ' + aux(sp) + ' <end>'\n",
        "    English_sens.append(en)\n",
        "    Spanish_sens.append(sp)"
      ],
      "metadata": {
        "id": "a3nbVPWa1N_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sen_length = []\n",
        "for idx in range(len(English_sens)):\n",
        "  en_len = len(English_sens[idx].split())\n",
        "  sp_len = len(Spanish_sens[idx].split())\n",
        "  sen_length.append(max(en_len, sp_len))"
      ],
      "metadata": {
        "id": "aCFVHDjO1-gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = max(sen_length)\n",
        "batch_size = 256\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "58sNzwN26jss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tokens(source_dataset): # <pad>:0, <unk>:the last token\n",
        "  dic = {}\n",
        "  for sen in source_dataset:\n",
        "    for word in sen.split():\n",
        "      if word not in dic:\n",
        "        dic.setdefault(word, 1)\n",
        "      else:\n",
        "        dic[word] += 1\n",
        "\n",
        "  token_dic = {}\n",
        "  token_dic.setdefault('<pad>', 0)\n",
        "\n",
        "  sort_dic = dict(sorted(dic.items(), key=lambda x:x[1], reverse=True))\n",
        "\n",
        "  for idx, word in enumerate(sort_dic):\n",
        "    token_dic[word] = idx + 1\n",
        "\n",
        "  token_dic.setdefault('<unk>', len(token_dic))\n",
        "\n",
        "  return token_dic\n",
        "SRC_Tokens = create_tokens(English_sens)\n",
        "TRG_Tokens = create_tokens(Spanish_sens)\n",
        "idx_to_tok_src = {v:k for (k,v) in SRC_Tokens.items()}\n",
        "idx_to_tok_trg = {v:k for (k,v) in TRG_Tokens.items()}"
      ],
      "metadata": {
        "id": "mgyFg62etRFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(sentence, tokens, max_len):\n",
        "  words = sentence.split()\n",
        "  for i in range(len(words)):\n",
        "    if words[i] in tokens:\n",
        "      words[i] = tokens[words[i]]\n",
        "    else:\n",
        "      words[i] = tokens['<unk>']\n",
        "  for _ in range(max_len-len(words)):\n",
        "    words.append(tokens['<pad>'])\n",
        "  return torch.tensor(words)\n",
        "\n",
        "print(tokenizer('i am fine bro', SRC_Tokens, MAX_LEN))\n",
        "print(tokenizer('<st> yo estoy bien <end>', TRG_Tokens, MAX_LEN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLCsBxTdXzoo",
        "outputId": "491c21e3-6400-4a92-a73e-e3e603a92602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([    1,   106,   694, 10903,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0])\n",
            "tensor([ 1, 98, 80, 57,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self, SRC, TRG, device):\n",
        "    self.SRC = SRC\n",
        "    self.TRG = TRG\n",
        "    self.device = device\n",
        "  def __len__(self):\n",
        "    return len(self.SRC)\n",
        "  def __getitem__(self, idx):\n",
        "    src, trg = self.SRC[idx], self.TRG[idx]\n",
        "    src = tokenizer(src, SRC_Tokens, MAX_LEN)\n",
        "    trg = tokenizer(trg, TRG_Tokens, MAX_LEN)\n",
        "    return src.to(self.device), trg.to(self.device)\n",
        "dataloader = DataLoader(MyDataset(English_sens, Spanish_sens, device),\n",
        "                        batch_size=batch_size)"
      ],
      "metadata": {
        "id": "y1-CW6m-638S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = len(SRC_Tokens)\n",
        "trg_vocab = len(TRG_Tokens)\n",
        "\n",
        "d_model = 40\n",
        "N = 1\n",
        "heads = 2\n",
        "\n",
        "model = Transformer(src_vocab, trg_vocab, d_model, N, heads, MAX_LEN).to(device)\n",
        "summary(model, [(batch_size, MAX_LEN), (batch_size, MAX_LEN)], dtypes=[torch.long, torch.long])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-zyXZmF6-RH",
        "outputId": "3e028e0e-fb99-4a02-97ab-7b61ae1409ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "Transformer                                   [256, 21, 24189]          --\n",
              "├─Encoder: 1-1                                [256, 21, 40]             --\n",
              "│    └─IO_Embedding: 2-1                      [256, 21, 40]             --\n",
              "│    │    └─Embedding: 3-1                    [256, 21, 40]             436,160\n",
              "│    └─PositionalEncoding: 2-2                [256, 21, 40]             --\n",
              "│    └─ModuleList: 2-3                        --                        --\n",
              "│    │    └─SingleEncoderLayer: 3-2           [256, 21, 40]             172,648\n",
              "├─Decoder: 1-2                                [256, 21, 40]             --\n",
              "│    └─IO_Embedding: 2-4                      [256, 21, 40]             --\n",
              "│    │    └─Embedding: 3-3                    [256, 21, 40]             967,560\n",
              "│    └─PositionalEncoding: 2-5                [256, 21, 40]             --\n",
              "│    └─ModuleList: 2-6                        --                        --\n",
              "│    │    └─SingleDecoderLayer: 3-4           [256, 21, 40]             179,288\n",
              "├─Linear: 1-3                                 [256, 21, 24189]          991,749\n",
              "===============================================================================================\n",
              "Total params: 2,747,405\n",
              "Trainable params: 2,747,405\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 703.23\n",
              "===============================================================================================\n",
              "Input size (MB): 0.09\n",
              "Forward/backward pass size (MB): 1252.61\n",
              "Params size (MB): 10.99\n",
              "Estimated Total Size (MB): 1263.68\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def translate(sentence, device):\n",
        "\n",
        "  sen_SRC = tokenizer(sentence, SRC_Tokens, MAX_LEN).unsqueeze(0).to(device)\n",
        "  sen_TRG = '<st>'\n",
        "\n",
        "  while '<end>' not in sen_TRG:\n",
        "\n",
        "    length = len(sen_TRG.split())\n",
        "    trg_input = tokenizer(sen_TRG, TRG_Tokens, MAX_LEN).unsqueeze(0)[:, :-1].to(device)\n",
        "    # see my_train code => remember: trg_input = trg[:,:-1]\n",
        "    preds = model(sen_SRC, trg_input, src_mask=None, trg_mask=None).squeeze()\n",
        "    next_word_idx = torch.argmax(preds, dim=-1)[length-1] #IMPORTANT\n",
        "    sen_TRG += (' ' + idx_to_tok_trg[next_word_idx.item()])\n",
        "\n",
        "  return sen_TRG"
      ],
      "metadata": {
        "id": "42QcPwTkN6w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 200\n",
        "print_step = 10\n",
        "lr = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "test_sen = \"we spent the night in a cheap hotel\"\n",
        "\n",
        "loss = train(model, optimizer, dataloader, epochs, translate, test_sen, device, print_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mFtLY2c7A9i",
        "outputId": "0a45c6e4-c3eb-4d11-e3d3-e69e0e2db9ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 -> Loss:  6.33125949\n",
            "we spent the night in a cheap hotel -> <st> El niño <end>\n",
            "Epoch: 11 -> Loss:  2.73496600\n",
            "we spent the night in a cheap hotel -> <st> Tenemos un hotel <end>\n",
            "Epoch: 21 -> Loss:  1.93771589\n",
            "we spent the night in a cheap hotel -> <st> Pasamos agua <end>\n",
            "Epoch: 31 -> Loss:  1.57507215\n",
            "we spent the night in a cheap hotel -> <st> Pasamos que un hotel en un hotel <end>\n",
            "Epoch: 41 -> Loss:  1.33963099\n",
            "we spent the night in a cheap hotel -> <st> Pasamos bien en la noche en la noche en un hotel económico <end>\n",
            "Epoch: 51 -> Loss:  1.18330918\n",
            "we spent the night in a cheap hotel -> <st> Pasamos general muy cómoda por una noche <end>\n",
            "Epoch: 61 -> Loss:  1.06112733\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el hotel económico <end>\n",
            "Epoch: 71 -> Loss:  0.96489214\n",
            "we spent the night in a cheap hotel -> <st> Pasamos estas pinturas cama <end>\n",
            "Epoch: 81 -> Loss:  0.89934241\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el hotel económico <end>\n",
            "Epoch: 91 -> Loss:  0.84106640\n",
            "we spent the night in a cheap hotel -> <st> Pasamos la noche <end>\n",
            "Epoch: 101 -> Loss:  0.79366745\n",
            "we spent the night in a cheap hotel -> <st> Pasamos estas puestos por un hotel económico <end>\n",
            "Epoch: 111 -> Loss:  0.74829398\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el hotel barato <end>\n",
            "Epoch: 121 -> Loss:  0.70634425\n",
            "we spent the night in a cheap hotel -> <st> Pasé la noche en la noche <end>\n",
            "Epoch: 131 -> Loss:  0.67440226\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el hotel económico <end>\n",
            "Epoch: 141 -> Loss:  0.64297407\n",
            "we spent the night in a cheap hotel -> <st> Quedamos todos los días barato dejaron los días barato <end>\n",
            "Epoch: 151 -> Loss:  0.61596176\n",
            "we spent the night in a cheap hotel -> <st> Pasamos estas horas llena <end>\n",
            "Epoch: 161 -> Loss:  0.59073434\n",
            "we spent the night in a cheap hotel -> <st> Pasamos estas fotos <end>\n",
            "Epoch: 171 -> Loss:  0.56966964\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el hotel económico <end>\n",
            "Epoch: 181 -> Loss:  0.54894926\n",
            "we spent the night in a cheap hotel -> <st> Hubo agua está tragando un hotel económico <end>\n",
            "Epoch: 191 -> Loss:  0.52912087\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el hotel barato a Ramos <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "print_step = 10\n",
        "lr = 5e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "test_sen = \"we spent the night in a cheap hotel\"\n",
        "\n",
        "loss = train(model, optimizer, dataloader, epochs, translate, test_sen, device, print_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYzgmbBaGAY6",
        "outputId": "08b1fc1c-6c8b-424b-fe0b-76ed17625db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 -> Loss:  0.49058775\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el hotel económico <end>\n",
            "Epoch: 11 -> Loss:  0.44193941\n",
            "we spent the night in a cheap hotel -> <st> Pasamos los ojos muy tristes <end>\n",
            "Epoch: 21 -> Loss:  0.42937651\n",
            "we spent the night in a cheap hotel -> <st> Pasamos harto un hotel menos un hotel peligroso <end>\n",
            "Epoch: 31 -> Loss:  0.41925283\n",
            "we spent the night in a cheap hotel -> <st> Pasamos la noche entrar a un hotel <end>\n",
            "Epoch: 41 -> Loss:  0.40831821\n",
            "we spent the night in a cheap hotel -> <st> Pasamos la noche <end>\n",
            "Epoch: 51 -> Loss:  0.40286723\n",
            "we spent the night in a cheap hotel -> <st> Pasamos todas roer que noche en un hotel barato de noche bajo en el hotel económico <end>\n",
            "Epoch: 61 -> Loss:  0.39488486\n",
            "we spent the night in a cheap hotel -> <st> Pasamos otro hotel económico <end>\n",
            "Epoch: 71 -> Loss:  0.38778390\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el hotel menos un hotel barato en un hotel económico <end>\n",
            "Epoch: 81 -> Loss:  0.37994853\n",
            "we spent the night in a cheap hotel -> <st> Pasamos breves Tengo la noche <end>\n",
            "Epoch: 91 -> Loss:  0.37428522\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el hotel económico <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "print_step = 10\n",
        "lr = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "test_sen = \"we spent the night in a cheap hotel\"\n",
        "\n",
        "loss = train(model, optimizer, dataloader, epochs, translate, test_sen, device, print_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJyfW271PQyn",
        "outputId": "7619190e-2137-44cb-db9e-2324c85e0cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 -> Loss:  0.35998609\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el hotel barato entrar un hotel <end>\n",
            "Epoch: 11 -> Loss:  0.33275364\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el príncipe Casi Haré el hotel barato <end>\n",
            "Epoch: 21 -> Loss:  0.32907799\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el hotel barato de noche <end>\n",
            "Epoch: 31 -> Loss:  0.32483271\n",
            "we spent the night in a cheap hotel -> <st> Pasamos la cama blanda debajo de noche <end>\n",
            "Epoch: 41 -> Loss:  0.32026825\n",
            "we spent the night in a cheap hotel -> <st> Hubo silencio es el hotel barato <end>\n",
            "Epoch: 51 -> Loss:  0.31809756\n",
            "we spent the night in a cheap hotel -> <st> Pasamos ninguna noche ¿Acaso Regresa carne <end>\n",
            "Epoch: 61 -> Loss:  0.31795131\n",
            "we spent the night in a cheap hotel -> <st> Pasamos peligro la multa dulce <end>\n",
            "Epoch: 71 -> Loss:  0.31438766\n",
            "we spent the night in a cheap hotel -> <st> Pasamos ninguna noche pescando <end>\n",
            "Epoch: 81 -> Loss:  0.31334435\n",
            "we spent the night in a cheap hotel -> <st> Pasamos la noche pescando <end>\n",
            "Epoch: 91 -> Loss:  0.31090495\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el hotel económico <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "print_step = 10\n",
        "lr = 5e-5\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "test_sen = \"we spent the night in a cheap hotel\"\n",
        "\n",
        "loss = train(model, optimizer, dataloader, epochs, translate, test_sen, device, print_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsiw5wYRac5l",
        "outputId": "b7500e3b-d8a2-4837-969e-88414cf2ca84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 -> Loss:  0.30984435\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el hotel económico <end>\n",
            "Epoch: 11 -> Loss:  0.30576440\n",
            "we spent the night in a cheap hotel -> <st> El lunes por un hotel económico <end>\n",
            "Epoch: 21 -> Loss:  0.30694344\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el hotel económico <end>\n",
            "Epoch: 31 -> Loss:  0.30241099\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el hotel barato de noche <end>\n",
            "Epoch: 41 -> Loss:  0.30056255\n",
            "we spent the night in a cheap hotel -> <st> Pasamos el hotel menos un hotel económico <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_en_sens = ['hello!', 'what is my name?',\n",
        "               'how are you?', 'she is pretty.',\n",
        "               'we spent the night in a cheap hotel']"
      ],
      "metadata": {
        "id": "Oju-3DlJrASO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for new_en_sen in new_en_sens:\n",
        "  spanish = translate(aux(new_en_sen).lower(), device)\n",
        "  spanish = spanish.replace('<st> ', '').replace(' <end>', '')\n",
        "  print(new_en_sen, '->', spanish)"
      ],
      "metadata": {
        "id": "XaGsGZSY7IeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69980ff1-82ef-47c6-d559-96e405fba0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello! -> Hola\n",
            "what is my name? -> ¿Cómo es mi nombre\n",
            "how are you? -> ¿Cómo haces\n",
            "she is pretty. -> Está muy hermosa\n",
            "we spent the night in a cheap hotel -> Pasamos el hotel barato de noche\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('params.pkl', 'wb') as f:\n",
        "  pickle.dump([SRC_Tokens, TRG_Tokens, idx_to_tok_trg], f)"
      ],
      "metadata": {
        "id": "fEln2g2fiDCy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}